{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "B9Yt5n1UtCQa",
        "outputId": "308a2eb1-1964-4cf0-ab83-a6d08ec41ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.15.3)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Collecting streamlit-folium\n",
            "  Downloading streamlit_folium-0.25.0-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.45.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: folium!=0.15.0,>=0.13 in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (0.19.7)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (0.8.1)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (2025.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.26.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m119.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m125.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "Downloading streamlit_folium-0.25.0-py3-none-any.whl (328 kB)\n",
            "Installing collected packages: watchdog, pydeck, streamlit, streamlit-folium\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4/4\u001b[0m [streamlit-folium]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pydeck-0.9.1 streamlit-1.46.1 streamlit-folium-0.25.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install streamlit pandas numpy matplotlib seaborn scipy wordcloud streamlit-folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_Pk8htw71vuS",
        "outputId": "8d729eca-f23e-481a-d0bc-c371dfa69094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [konlpy]\n",
            "\u001b[1A\u001b[2KSuccessfully installed JPype1-1.5.2 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dzWMOFkptXod",
        "outputId": "ea70c2b5-7268-4547-f983-5db27bbe69a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-07-07 00:16:13.427 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing NanumGothic font...\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Selecting previously unselected package fonts-nanum.\n",
            "(Reading database ... 126308 files and directories currently installed.)\n",
            "Preparing to unpack .../fonts-nanum_20200506-1_all.deb ...\n",
            "Unpacking fonts-nanum (20200506-1) ...\n",
            "Setting up fonts-nanum (20200506-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 12 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/usr/share/fonts/truetype: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n",
            "/usr/share/fonts/truetype/nanum: skipping, looped directory detected\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import folium\n",
        "from streamlit_folium import folium_static\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from folium.plugins import HeatMap\n",
        "from PIL import Image\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from scipy.stats import pearsonr\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# --- Colab Environment Setup for Korean Fonts ---\n",
        "# These commands install Nanum Gothic font and refresh font cache in Colab.\n",
        "# They need to be run once in the Colab environment.\n",
        "# Check if font is already installed to avoid unnecessary re-installation\n",
        "try:\n",
        "    fm.findfont('NanumGothic', fallback_to_default=False)\n",
        "    print(\"NanumGothic font already installed.\")\n",
        "except ValueError:\n",
        "    print(\"Installing NanumGothic font...\")\n",
        "    # These commands run on the Colab Linux environment\n",
        "    !apt-get update -qq\n",
        "    !apt-get install fonts-nanum -qq\n",
        "    !fc-cache -fv\n",
        "    !rm -rf ~/.cache/matplotlib\n",
        "\n",
        "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "fontprop = fm.FontProperties(fname=font_path, size=10)\n",
        "plt.rcParams['font.family'] = 'NanumGothic'\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okXlNeI6s-4O",
        "outputId": "cff585be-4a2f-4c1d-cfed-9ac4e26b394c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import folium\n",
        "from streamlit_folium import folium_static, st_folium\n",
        "from folium import plugins\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.font_manager as fm\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "from scipy.stats import pearsonr\n",
        "from konlpy.tag import Okt\n",
        "from collections import Counter\n",
        "import time\n",
        "import subprocess # This line should be here\n",
        "import matplotlib.patches as patches\n",
        "import random\n",
        "from datetime import datetime, timedelta # datetimeê³¼ timedeltaë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "# --- í˜ì´ì§€ ì„¤ì • ---\n",
        "st.set_page_config(\n",
        "    page_title=\"ì „ê¸°ì°¨ ì¸í”„ë¼ ëŒ€ì‹œë³´ë“œ\",\n",
        "    page_icon=\"ğŸ”Œ\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# --- Colab Environment Setup for Korean Fonts (Moved to main for better control) ---\n",
        "# This part is now handled within the main() function to ensure it runs once.\n",
        "\n",
        "# --- Data Loading and Preprocessing ---\n",
        "@st.cache_data\n",
        "def load_common_data():\n",
        "    \"\"\"ê³µí†µ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\"\"\"\n",
        "    car_path = \"ele_car_now_half.csv\"\n",
        "    charger_path = \"ele_car_charger_final.csv\"\n",
        "    allcar_path = \"var_car.csv\"\n",
        "    crawling_path = \"ele_crawling.csv\"\n",
        "    stopwords_path = \"stopwords1.txt\"\n",
        "\n",
        "    data_dict = {}\n",
        "\n",
        "    try:\n",
        "        data_dict['df_car'] = pd.read_csv(car_path, encoding='UTF-8')\n",
        "        data_dict['df_charger'] = pd.read_csv(charger_path, encoding='UTF-8')\n",
        "        data_dict['df_allcar'] = pd.read_csv(allcar_path, encoding='UTF-8')\n",
        "        data_dict['df_crawling'] = pd.read_csv(crawling_path, encoding='cp949')\n",
        "    except FileNotFoundError as e:\n",
        "        st.error(f\"ì—ëŸ¬: í•„ìš”í•œ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e})\")\n",
        "        st.markdown(f\"**ë‹¤ìŒ íŒŒì¼ë“¤ì´ Colab í™˜ê²½ì— ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”:**\")\n",
        "        st.markdown(f\"- `{car_path}`\")\n",
        "        st.markdown(f\"- `{charger_path}`\")\n",
        "        st.markdown(f\"- `{allcar_path}`\")\n",
        "        st.markdown(f\"- `{crawling_path}`\")\n",
        "        st.markdown(f\"- `{stopwords_path}` (ì›Œë“œí´ë¼ìš°ë“œìš©)\")\n",
        "        st.stop()\n",
        "    except Exception as e:\n",
        "        st.error(f\"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "        st.stop()\n",
        "\n",
        "    for df_name in ['df_car', 'df_charger', 'df_allcar']:\n",
        "        if df_name in data_dict and 'full_date' in data_dict[df_name].columns:\n",
        "            data_dict[df_name]['full_date'] = pd.to_datetime(data_dict[df_name]['full_date'])\n",
        "\n",
        "    df_ev_chg_merge = pd.merge(data_dict['df_car'][['name', 'full_date', 'year', 'car']],\n",
        "                                 data_dict['df_charger'][['name', 'full_date', 'year', 'total']],\n",
        "                                 on=['name', 'full_date', 'year'])\n",
        "    df_ev_chg_merge['ev_per_charger'] = df_ev_chg_merge['car'] / df_ev_chg_merge['total']\n",
        "    df_ev_chg_merge = df_ev_chg_merge.replace([np.inf, -np.inf], np.nan).dropna(subset=['ev_per_charger'])\n",
        "\n",
        "    latest_year_data = df_ev_chg_merge[df_ev_chg_merge['year'] == df_ev_chg_merge['year'].max()]\n",
        "\n",
        "    regional_summary = latest_year_data.groupby('name').agg(\n",
        "        ev_counts=('car', 'sum'),\n",
        "        charger_counts=('total', 'sum'),\n",
        "        avg_ev_per_charger=('ev_per_charger', 'mean')\n",
        "    ).reset_index()\n",
        "\n",
        "    regions = regional_summary['name'].tolist()\n",
        "    ev_counts = regional_summary['ev_counts'].tolist()\n",
        "    charger_counts = regional_summary['charger_counts'].tolist()\n",
        "\n",
        "    colors = plt.cm.tab20.colors[:len(regions)]\n",
        "\n",
        "    car_total_yearly = data_dict['df_car'].groupby('year')['car'].sum().reset_index()\n",
        "    charger_total_yearly = data_dict['df_charger'].groupby('year')['total'].sum().reset_index()\n",
        "\n",
        "    df_total_yearly = pd.merge(car_total_yearly, charger_total_yearly, on='year')\n",
        "    df_total_yearly['car_thousands'] = df_total_yearly['car'] / 1000\n",
        "    df_total_yearly['charger_thousands'] = df_total_yearly['total'] / 1000\n",
        "\n",
        "    years = df_total_yearly['year'].astype(str).tolist()\n",
        "    total_ev_yearly = df_total_yearly['car_thousands'].tolist()\n",
        "    total_charger_yearly = df_total_yearly['charger_thousands'].tolist()\n",
        "\n",
        "    df_ev_allcar_merge = pd.merge(data_dict['df_car'][['name', 'full_date', 'year', 'car']],\n",
        "                                  data_dict['df_allcar'][['name', 'full_date', 'year', 'allcar']],\n",
        "                                  on=['name', 'full_date', 'year'])\n",
        "    df_ev_allcar_merge['ev_ratio'] = df_ev_allcar_merge['car'] / df_ev_allcar_merge['allcar'] * 100\n",
        "    df_ev_allcar_merge = df_ev_allcar_merge.replace([np.inf, -np.inf], np.nan).dropna(subset=['ev_ratio'])\n",
        "\n",
        "    all_text = ' '.join(data_dict['df_crawling'].iloc[:, 0].dropna().astype(str))\n",
        "    okt = Okt()\n",
        "    nouns = okt.nouns(all_text)\n",
        "\n",
        "    stopwords = set()\n",
        "    try:\n",
        "        with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
        "            stopwords = set(word.strip() for word in f if word.strip())\n",
        "    except FileNotFoundError:\n",
        "        st.warning(f\"Stopwords file '{stopwords_path}' not found. Word cloud will not filter stopwords.\")\n",
        "    except Exception as e:\n",
        "        st.warning(f\"Error loading stopwords: {e}. Word cloud will not filter stopwords.\")\n",
        "\n",
        "    filtered_nouns = [noun for noun in nouns if len(noun) > 1 and noun not in stopwords]\n",
        "    word_count = Counter(filtered_nouns)\n",
        "\n",
        "    data_dict.update({\n",
        "        'regional_summary': regional_summary,\n",
        "        'regions': regions,\n",
        "        'ev_counts': ev_counts,\n",
        "        'charger_counts': charger_counts,\n",
        "        'colors': colors,\n",
        "        'years': years,\n",
        "        'total_ev_yearly': total_ev_yearly,\n",
        "        'total_charger_yearly': total_charger_yearly,\n",
        "        'df_ev_chg_merge': df_ev_chg_merge,\n",
        "        'df_ev_allcar_merge': df_ev_allcar_merge,\n",
        "        'word_count': word_count\n",
        "    })\n",
        "    return data_dict\n",
        "\n",
        "@st.cache_data(ttl=3600)\n",
        "def load_charger_location_data(file_path='/content/ì „ê¸°ì°¨ì¶©ì „ì†Œ2.xlsx'):\n",
        "    \"\"\"\n",
        "    ì¶©ì „ì†Œ ìœ„ì¹˜ ë°ì´í„° (ìœ„ë„, ê²½ë„)ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        df = pd.read_excel(file_path, engine='openpyxl', dtype_backend='pyarrow')\n",
        "\n",
        "        required_columns = ['ìœ„ë„ê²½ë„', 'ì¶©ì „ì†Œëª…', 'ì£¼ì†Œ', 'ì‹œë„', 'êµ°êµ¬', 'ì„¤ì¹˜ë…„ë„']\n",
        "        existing_columns = [col for col in required_columns if col in df.columns]\n",
        "        df = df[existing_columns]\n",
        "\n",
        "        if 'ìœ„ë„ê²½ë„' in df.columns:\n",
        "            df[['ìœ„ë„', 'ê²½ë„']] = df['ìœ„ë„ê²½ë„'].str.split(',', expand=True)\n",
        "            df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')\n",
        "            df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')\n",
        "        else:\n",
        "            st.error(\"Error: 'ìœ„ë„ê²½ë„' ì»¬ëŸ¼ì„ Excel íŒŒì¼ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        df['ì„¤ì¹˜ë…„ë„'] = pd.to_numeric(df['ì„¤ì¹˜ë…„ë„'], errors='coerce').astype('Int64')\n",
        "\n",
        "        df_clean = df.dropna(subset=['ìœ„ë„', 'ê²½ë„', 'ì„¤ì¹˜ë…„ë„'])\n",
        "\n",
        "        df_clean = df_clean[\n",
        "            (df_clean['ìœ„ë„'] >= 33.0) & (df_clean['ìœ„ë„'] <= 39.0) &\n",
        "            (df_clean['ê²½ë„'] >= 124.0) & (df_clean['ê²½ë„'] <= 132.0)\n",
        "        ].reset_index(drop=True)\n",
        "\n",
        "        load_time = time.time() - start_time\n",
        "        #st.success(f\"ì¶©ì „ì†Œ ìœ„ì¹˜ ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({load_time:.2f}ì´ˆ, {len(df_clean):,}ê°œ ì¶©ì „ì†Œ)\")\n",
        "        return df_clean\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        st.error(f\"Error: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Colab í™˜ê²½ì— ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "        return pd.DataFrame()\n",
        "    except Exception as e:\n",
        "        st.error(f\"ì¶©ì „ì†Œ ìœ„ì¹˜ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# --- ì‚¬ì´ë“œë°” ë©”ë‰´ ---\n",
        "def render_sidebar():\n",
        "    \"\"\"ì‚¬ì´ë“œë°” ë©”ë‰´ ë Œë”ë§\"\"\"\n",
        "    st.sidebar.title(\"ì¹´í…Œê³ ë¦¬\")\n",
        "\n",
        "    # ê°„ë‹¨í•œ CSS\n",
        "    st.markdown(\"\"\"\n",
        "      <style>\n",
        "          /* ì‚¬ì´ë“œë°” ì»¨í…Œì´ë„ˆ íŒ¨ë”© ì¡°ì • */\n",
        "          section[data-testid=\"stSidebar\"] > div {\n",
        "              padding-left: 1rem;\n",
        "              padding-right: 1rem;\n",
        "          }\n",
        "\n",
        "          /* ì‚¬ì´ë“œë°” ë²„íŠ¼ ì „ì²´ ë„ˆë¹„ */\n",
        "          section[data-testid=\"stSidebar\"] .stButton {\n",
        "              width: 100% !important;\n",
        "          }\n",
        "\n",
        "          section[data-testid=\"stSidebar\"] .stButton > button {\n",
        "              width: 100% !important;\n",
        "              text-align: left !important;\n",
        "              justify-content: flex-start !important;\n",
        "              padding: 0.5rem 1rem !important;\n",
        "              margin: 0.25rem 0 !important;\n",
        "              min-height: 2.5rem !important;\n",
        "              border-radius: 0.5rem !important;\n",
        "              background-color: #f0f2f6 !important;\n",
        "              border: 1px solid transparent !important;\n",
        "              transition: all 0.2s ease !important;\n",
        "          }\n",
        "\n",
        "          /* ë²„íŠ¼ í˜¸ë²„ íš¨ê³¼ */\n",
        "          section[data-testid=\"stSidebar\"] .stButton > button:hover {\n",
        "              background-color: #e6f3ff !important;\n",
        "              border-left: 3px solid #4ECDC4 !important;\n",
        "              padding-left: calc(1rem - 2px) !important;\n",
        "              transform: translateX(2px);\n",
        "          }\n",
        "\n",
        "          /* ë²„íŠ¼ í´ë¦­(í™œì„±) ìƒíƒœ */\n",
        "          section[data-testid=\"stSidebar\"] .stButton > button:active,\n",
        "          section[data-testid=\"stSidebar\"] .stButton > button:focus {\n",
        "              background-color: #4ECDC4 !important;\n",
        "              color: white !important;\n",
        "              box-shadow: 0 2px 4px rgba(0,0,0,0.1) !important;\n",
        "              outline: none !important;\n",
        "          }\n",
        "\n",
        "          /* ë²„íŠ¼ ë‚´ë¶€ í…ìŠ¤íŠ¸ */\n",
        "          section[data-testid=\"stSidebar\"] .stButton > button > div {\n",
        "              text-align: left !important;\n",
        "              width: 100% !important;\n",
        "          }\n",
        "\n",
        "          section[data-testid=\"stSidebar\"] .stButton > button p {\n",
        "              text-align: left !important;\n",
        "              margin: 0 !important;\n",
        "              font-weight: 500 !important;\n",
        "          }\n",
        "\n",
        "          /* ì‚¬ì´ë“œë°” ì œëª© ìŠ¤íƒ€ì¼ */\n",
        "          section[data-testid=\"stSidebar\"] h1 {\n",
        "              font-size: 1.5rem !important;\n",
        "              margin-bottom: 1.5rem !important;\n",
        "              padding-bottom: 0.5rem !important;\n",
        "              border-bottom: 2px solid #4ECDC4 !important;\n",
        "          }\n",
        "      </style>\n",
        "      \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    if 'current_page' not in st.session_state:\n",
        "        st.session_state.current_page = \"í‚¤ì›Œë“œ ë¶„ì„\"\n",
        "\n",
        "    pages = {\n",
        "        \"ì£¼ìš” í† í”½\": \"menu_keywords\",\n",
        "        \"ì¶©ì „ì†Œ í˜„í™©\": \"menu_heatmap_new\",\n",
        "        \"ìƒê´€ë¶„ì„ê²°ê³¼\": \"menu_correlation\",\n",
        "        \"ì¸í”„ë¼ í˜„í™©\": \"menu_infrastructure\",\n",
        "        \"ë¶„ì„ ë¦¬í¬íŠ¸\": \"menu_conclusion\",\n",
        "        \"FAQ\" : \"menu_FAQ\"\n",
        "    }\n",
        "\n",
        "    for page, key in pages.items():\n",
        "        if st.sidebar.button(page, key=key):\n",
        "            st.session_state.current_page = page\n",
        "\n",
        "# --- Plotting Functions ---\n",
        "\n",
        "def create_pie_chart(data, title):\n",
        "    \"\"\"íŒŒì´ ì°¨íŠ¸ ìƒì„±\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    wedges, texts, autotexts = ax.pie(\n",
        "        data['ev_counts'],\n",
        "        labels=data['regions'],\n",
        "        autopct='%1.1f%%',\n",
        "        startangle=90,\n",
        "        colors=data['colors']\n",
        "    )\n",
        "    ax.set_title(title, fontsize=14, pad=20)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def create_correlation_plot_regional(data):\n",
        "    \"\"\"ì§€ì—­ë³„ ìƒê´€ê´€ê³„ ì‚°í¬ë„ ìƒì„± (ì „ê¸°ì°¨ ëŒ€ìˆ˜ vs ì¶©ì „ì†Œ ê°œìˆ˜)\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    correlation = np.corrcoef(data['ev_counts'], data['charger_counts'])[0, 1]\n",
        "\n",
        "    scatter = ax.scatter(data['ev_counts'], data['charger_counts'],\n",
        "                             c=data['colors'], s=150, alpha=0.7, edgecolors='black')\n",
        "\n",
        "    z = np.polyfit(data['ev_counts'], data['charger_counts'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot(data['ev_counts'], p(data['ev_counts']), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "    for i, region in enumerate(data['regions']):\n",
        "        ax.annotate(region, (data['ev_counts'][i], data['charger_counts'][i]),\n",
        "                             xytext=(5, 5), textcoords='offset points', fontsize=10)\n",
        "\n",
        "    ax.set_xlabel('ì „ê¸°ì°¨ ë“±ë¡ ëŒ€ìˆ˜')\n",
        "    ax.set_ylabel('ì¶©ì „ì†Œ ê°œìˆ˜')\n",
        "    ax.set_title(f'ì§€ì—­ë³„ ì „ê¸°ì°¨ vs ì¶©ì „ì†Œ ìƒê´€ê´€ê³„ (r = {correlation:.3f})')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    return fig, correlation\n",
        "\n",
        "def create_time_series(data):\n",
        "    \"\"\"ì—°ë„ë³„ ì „ê¸°ì°¨ ë° ì¶©ì „ì†Œ ì¦ê°€ ì¶”ì´ ì‹œê³„ì—´ ì°¨íŠ¸ ìƒì„±\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    ax2 = ax.twinx()\n",
        "\n",
        "    line1 = ax.plot(data['years'], data['total_ev_yearly'], 'b-o', linewidth=3, label='ì „ê¸°ì°¨ (ì²œ ëŒ€)')\n",
        "    ax.set_ylabel('ì „ê¸°ì°¨ ë“±ë¡ëŒ€ìˆ˜ (ì²œ ëŒ€)', color='blue')\n",
        "    ax.tick_params(axis='y', labelcolor='blue')\n",
        "\n",
        "    line2 = ax2.plot(data['years'], data['total_charger_yearly'], 'g-s', linewidth=3, label='ì¶©ì „ì†Œ (ì²œ ê°œ)')\n",
        "    ax2.set_ylabel('ì¶©ì „ì†Œ ê°œìˆ˜ (ì²œ ê°œ)', color='green')\n",
        "    ax2.tick_params(axis='y', labelcolor='green')\n",
        "\n",
        "    ax.set_xlabel('ì—°ë„')\n",
        "    ax.set_title('ì „ê¸°ì°¨ ë° ì¶©ì „ì†Œ ì¦ê°€ ì¶”ì´')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    lines = line1 + line2\n",
        "    labels = [l.get_label() for l in lines]\n",
        "    ax.legend(lines, labels, loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def plot_ev_per_charger_2024(df_merged_data):\n",
        "    st.header(\"2024ë…„ ì§€ì—­ë³„ ì¶©ì „ê¸°ë‹¹ ì „ê¸°ì°¨ ìˆ˜\")\n",
        "    df_2024 = df_merged_data[df_merged_data['year'] == 2024]\n",
        "    if df_2024.empty:\n",
        "        st.warning(\"2024ë…„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return\n",
        "\n",
        "    df_bar = df_2024.groupby('name')['ev_per_charger'].mean().reset_index()\n",
        "    df_bar = df_bar.sort_values(by='ev_per_charger', ascending=False)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    bars = ax.bar(df_bar['name'], df_bar['ev_per_charger'], color='skyblue')\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, height + 0.3, f'{height:.1f}',\n",
        "                        ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "    ax.set_title(\"2024ë…„ ì§€ì—­ë³„ ì¶©ì „ê¸°ë‹¹ ì „ê¸°ì°¨ ìˆ˜\", fontsize=14)\n",
        "    ax.set_xlabel(\"ì§€ì—­\")\n",
        "    ax.set_ylabel(\"ì „ê¸°ì°¨ ëŒ€ìˆ˜ (ì¶©ì „ê¸° 1ê¸°ë‹¹)\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_ev_per_charger_timeseries(df_merged_data):\n",
        "    st.header(\"ì§€ì—­ë³„ ì¶©ì „ê¸°ë‹¹ ì „ê¸°ì°¨ ìˆ˜ ë³€í™” ì¶”ì´\")\n",
        "    df_grouped = df_merged_data.groupby(['full_date', 'name'])['ev_per_charger'].mean().reset_index()\n",
        "    pivot = df_grouped.pivot(index='full_date', columns='name', values='ev_per_charger')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    pivot.plot(marker='s', ax=ax)\n",
        "    ax.set_title(\"ì§€ì—­ë³„ ì¶©ì „ê¸°ë‹¹ ì „ê¸°ì°¨ ìˆ˜\", fontsize=14)\n",
        "    ax.set_xlabel(\"ë‚ ì§œ\")\n",
        "    ax.set_ylabel(\"ì „ê¸°ì°¨ ëŒ€ìˆ˜ (ì¶©ì „ê¸° 1ê¸°ë‹¹)\")\n",
        "    ax.legend(title=\"ì§€ì—­\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_ev_ratio_timeseries(df_merged_data):\n",
        "    st.header(\"ì§€ì—­ë³„ ì „ê¸°ì°¨ ë¹„ìœ¨ ë³€í™” ì¶”ì´\")\n",
        "    df_grouped = df_merged_data.groupby(['full_date', 'name'])['ev_ratio'].mean().reset_index()\n",
        "    pivot = df_grouped.pivot(index='full_date', columns='name', values='ev_ratio')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(14, 7))\n",
        "    pivot.plot(marker='o', ax=ax)\n",
        "    ax.set_title(\"ì§€ì—­ë³„ ì „ê¸°ì°¨ ë¹„ìœ¨ ë³€í™” (%)\", fontsize=14)\n",
        "    ax.set_xlabel(\"ë‚ ì§œ\")\n",
        "    ax.set_ylabel(\"ì „ê¸°ì°¨ ë¹„ìœ¨ (%)\")\n",
        "    ax.legend(title=\"ì§€ì—­\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "def plot_car_charger_correlation_national(df_car_data, df_charger_data):\n",
        "    st.header(\"ì „êµ­ ì „ê¸°ì°¨ ìˆ˜ì™€ ì¶©ì „ê¸° ìˆ˜ ìƒê´€ê´€ê³„\")\n",
        "    df_car_corr = df_car_data.copy()\n",
        "    df_charger_corr = df_charger_data.copy()\n",
        "\n",
        "    df_car_corr['full_date'] = pd.to_datetime(df_car_corr['full_date'])\n",
        "    df_charger_corr['full_date'] = pd.to_datetime(df_charger_corr['full_date'])\n",
        "\n",
        "    car_total = df_car_corr.groupby('full_date')['car'].sum().reset_index()\n",
        "    char_total = df_charger_corr.groupby('full_date')['total'].sum().reset_index()\n",
        "\n",
        "    df_total = pd.merge(car_total, char_total, on='full_date')\n",
        "    df_total['car'] = df_total['car'] / 1000\n",
        "    df_total['total'] = df_total['total'] / 1000\n",
        "\n",
        "    corr, p_value = pearsonr(df_total['car'], df_total['total'])\n",
        "\n",
        "    st.write(f\"**ì „ì²´ ê¸°ê°„ ì „ê¸°ì°¨ ìˆ˜ì™€ ì¶©ì „ê¸° ìˆ˜ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜:** `{corr:.4f}` (ìœ ì˜í™•ë¥ : `{p_value:.4f}`)\")\n",
        "\n",
        "    def thousands(x, pos):\n",
        "        return f'{int(x):,}'\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.plot(df_total['full_date'], df_total['car'], marker='o', label='ì „ê¸°ì°¨ ìˆ˜ (ì²œ ëŒ€)')\n",
        "    ax.plot(df_total['full_date'], df_total['total'], marker='x', linestyle='--', label='ì¶©ì „ê¸° ìˆ˜ (ì²œ ëŒ€)')\n",
        "    ax.set_xlabel(\"ë‚ ì§œ\")\n",
        "    ax.set_ylabel(\"ëŒ€ìˆ˜ (ì²œ ë‹¨ìœ„)\")\n",
        "    ax.set_title(f\"ì „êµ­ ì „ê¸°ì°¨ ìˆ˜ vs ì¶©ì „ê¸° ìˆ˜\\n(í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜: {corr:.2f})\", fontsize=14)\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "    ax.yaxis.set_major_formatter(FuncFormatter(thousands))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "    plt.close(fig)\n",
        "\n",
        "    st.subheader(\"ë³€í™”ëŸ‰ ê¸°ë°˜ ìƒê´€ê´€ê³„ ë¶„ì„\")\n",
        "    df_total['car_diff'] = df_total['car'].diff()\n",
        "    df_total['total_diff'] = df_total['total'].diff()\n",
        "    df_diff = df_total.dropna(subset=['car_diff', 'total_diff'])\n",
        "\n",
        "    if not df_diff.empty:\n",
        "        corr_diff, p_value_diff = pearsonr(df_diff['car_diff'], df_diff['total_diff'])\n",
        "        st.write(f\"**ì›”ë³„ ì¦ê°€ëŸ‰ ê¸°ë°˜ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜:** `{corr_diff:.4f}` (ìœ ì˜í™•ë¥ : `{p_value_diff:.4f}`)\")\n",
        "    else:\n",
        "        st.write(\"ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë³€í™”ëŸ‰ ê¸°ë°˜ ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "# --- Main App Logic ---\n",
        "def main():\n",
        "    # --- í•œê¸€ í°íŠ¸ ì„¤ì • ---\n",
        "    font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "    if 'font_installed' not in st.session_state:\n",
        "        try:\n",
        "            fm.findfont('NanumGothic', fallback_to_default=False)\n",
        "            plt.rcParams['font.family'] = 'NanumGothic'\n",
        "            plt.rcParams['axes.unicode_minus'] = False\n",
        "            st.session_state.font_installed = True\n",
        "            print(\"NanumGothic font already configured.\")\n",
        "        except ValueError:\n",
        "            print(\"Installing NanumGothic font...\")\n",
        "            try:\n",
        "                st.info(\"ë‚˜ëˆ”ê³ ë”• í°íŠ¸ë¥¼ ì„¤ì¹˜ ì¤‘ì…ë‹ˆë‹¤. (Colab í™˜ê²½)\")\n",
        "                # Use subprocess.run for shell commands\n",
        "                subprocess.run(['apt-get', 'update', '-qq'], check=True)\n",
        "                subprocess.run(['apt-get', 'install', 'fonts-nanum', '-qq'], check=True)\n",
        "                subprocess.run(['fc-cache', '-fv'], check=True)\n",
        "                subprocess.run(['rm', '-rf', '~/.cache/matplotlib'], check=True)\n",
        "\n",
        "                plt.rcParams['font.family'] = 'NanumGothic'\n",
        "                plt.rcParams['axes.unicode_minus'] = False\n",
        "                st.session_state.font_installed = True\n",
        "                st.success(\"ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ì„¤ì¹˜ ë° ì„¤ì • ì™„ë£Œ.\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                st.warning(f\"ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ì„¤ì¹˜ ì˜¤ë¥˜ (ì‰˜ ëª…ë ¹ ì‹¤í–‰ ì‹¤íŒ¨): {e}. ê·¸ë˜í”„ì— í•œê¸€ì´ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "                plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "                plt.rcParams['axes.unicode_minus'] = False\n",
        "                st.session_state.font_installed = False\n",
        "            except Exception as e:\n",
        "                st.warning(f\"ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ì„¤ì¹˜ ë˜ëŠ” ì„¤ì • ì˜¤ë¥˜: {e}. ê·¸ë˜í”„ì— í•œê¸€ì´ ì˜¬ë°”ë¥´ê²Œ í‘œì‹œë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "                plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "                plt.rcParams['axes.unicode_minus'] = False\n",
        "                st.session_state.font_installed = False\n",
        "        except Exception as e:\n",
        "            st.warning(f\"í°íŠ¸ ì„¤ì • í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. ê¸°ë³¸ í°íŠ¸ë¡œ í‘œì‹œë©ë‹ˆë‹¤.\")\n",
        "            plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "            plt.rcParams['axes.unicode_minus'] = False\n",
        "            st.session_state.font_installed = False\n",
        "\n",
        "\n",
        "    with st.spinner(\"í•„ìˆ˜ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...\"):\n",
        "        common_data = load_common_data()\n",
        "    with st.spinner(\"ì¶©ì „ì†Œ ìœ„ì¹˜ ë°ì´í„°ë¥¼ ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...\"):\n",
        "        charger_location_df = load_charger_location_data()\n",
        "\n",
        "    render_sidebar()\n",
        "\n",
        "    if st.session_state.current_page == \"ì¶©ì „ì†Œ í˜„í™©\":\n",
        "        st.title(\"ì „ê¸°ì°¨ ì¶©ì „ì†Œ í˜„í™© ëŒ€ì‹œë³´ë“œ\")\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "        col_main_map, col_right_panel_map = st.columns([4, 1])\n",
        "\n",
        "        with col_right_panel_map:\n",
        "            st.subheader(\"ì§€ë„ ì„¤ì •\")\n",
        "\n",
        "            if not charger_location_df.empty:\n",
        "                min_year = int(charger_location_df['ì„¤ì¹˜ë…„ë„'].min())\n",
        "                max_year = int(charger_location_df['ì„¤ì¹˜ë…„ë„'].max())\n",
        "            else:\n",
        "                min_year = 2010\n",
        "                max_year = 2024\n",
        "\n",
        "            # st.markdown(\"ì¶©ì „ì†Œ ì„¤ì¹˜ ì—°ë„\")\n",
        "            year_range = st.slider(\n",
        "                \"ì„¤ì¹˜ ì—°ë„\",\n",
        "                min_value=min_year,\n",
        "                max_value=max_year,\n",
        "                value=(min_year, max_year),\n",
        "                step=1,\n",
        "                key=\"map_year_slider\",\n",
        "                label_visibility=\"hidden\"\n",
        "            )\n",
        "            st.markdown(\"\")\n",
        "            # st.markdown(\"ì§€ì—­ ì„ íƒ\")\n",
        "            if not charger_location_df.empty and 'ì‹œë„' in charger_location_df.columns:\n",
        "                regions = ['ì „ì²´'] + sorted(charger_location_df['ì‹œë„'].unique().tolist())\n",
        "            else:\n",
        "                regions = ['ì „ì²´']\n",
        "            selected_region = st.selectbox(\"ì‹œë„ ì„ íƒ\", regions, key=\"map_region_select\")\n",
        "            st.markdown(\"\")\n",
        "\n",
        "            # st.markdown(\"ì§€ë„ ì˜µì…˜\")\n",
        "            show_heatmap = st.checkbox(\"íˆíŠ¸ë§µ í‘œì‹œ\", value=True, key=\"map_show_heatmap\")\n",
        "            show_markers = st.checkbox(\"ë§ˆì»¤ í‘œì‹œ\", value=False, key=\"map_show_markers\")\n",
        "\n",
        "            # st.markdown(\"íˆíŠ¸ë§µ ë°ì´í„° ê°œìˆ˜\")\n",
        "            st.markdown(\"\")\n",
        "\n",
        "            heatmap_limit = 5000\n",
        "            if show_heatmap:\n",
        "                heatmap_limit = st.slider(\n",
        "                    \"ì¶©ì „ì†Œ ìˆ˜\",\n",
        "                    min_value=1000,\n",
        "                    max_value=min(20000, len(charger_location_df) if not charger_location_df.empty else 10000),\n",
        "                    value=min(5000, len(charger_location_df) if not charger_location_df.empty else 5000),\n",
        "                    step=1000,\n",
        "                    help=\"ë” ì ì€ ìˆ˜ë¡œ ì„¤ì •í•˜ë©´ ì†ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤\",\n",
        "                    key=\"heatmap_limit_slider\",\n",
        "                    # label_visibility=\"hidden\"\n",
        "                )\n",
        "\n",
        "            marker_limit = 500\n",
        "            if show_markers:\n",
        "                marker_limit = st.slider(\n",
        "                    \"ì¶©ì „ì†Œ ìˆ˜\",\n",
        "                    min_value=100,\n",
        "                    max_value=min(5000, len(charger_location_df) if not charger_location_df.empty else 2000),\n",
        "                    value=min(500, len(charger_location_df) if not charger_location_df.empty else 500),\n",
        "                    step=100,\n",
        "                    help=\"ë„ˆë¬´ ë§ì€ ë§ˆì»¤ëŠ” ì„±ëŠ¥ì„ ì €í•˜ì‹œí‚µë‹ˆë‹¤\",\n",
        "                    key=\"marker_limit_slider\",\n",
        "                    # label_visibility=\"hidden\"\n",
        "                )\n",
        "\n",
        "\n",
        "        with col_main_map:\n",
        "            col_map_stats_1, col_map_stats_2, col_map_stats_3 = st.columns(3)\n",
        "\n",
        "            @st.cache_data\n",
        "            def filter_map_data(df, year_start, year_end, region):\n",
        "                filtered_df = df[\n",
        "                    (df['ì„¤ì¹˜ë…„ë„'] >= year_start) &\n",
        "                    (df['ì„¤ì¹˜ë…„ë„'] <= year_end)\n",
        "                ]\n",
        "                if region != 'ì „ì²´':\n",
        "                    filtered_df = filtered_df[filtered_df['ì‹œë„'] == region]\n",
        "                return filtered_df\n",
        "\n",
        "            filtered_charger_df = filter_map_data(charger_location_df, year_range[0], year_range[1], selected_region)\n",
        "\n",
        "\n",
        "            with col_map_stats_1:\n",
        "                st.metric(\"ì¶©ì „ì†Œ ìˆ˜\", f\"{len(filtered_charger_df):,}ê°œ\")\n",
        "\n",
        "            with col_map_stats_2:\n",
        "                regions_count_map = filtered_charger_df['ì‹œë„'].nunique() if 'ì‹œë„' in filtered_charger_df.columns else 0\n",
        "                st.metric(\"ì§€ì—­\", f\"{regions_count_map}ê°œ\")\n",
        "\n",
        "            with col_map_stats_3:\n",
        "                if year_range[0] != year_range[1]:\n",
        "                    years_count_map = year_range[1] - year_range[0] + 1\n",
        "                    st.metric(\"ì„ íƒ ê¸°ê°„\", f\"{years_count_map}ë…„\")\n",
        "                else:\n",
        "                    st.metric(\"ì„ íƒ ì—°ë„\", f\"{year_range[0]}ë…„\")\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "\n",
        "            if not filtered_charger_df.empty:\n",
        "                if selected_region != 'ì „ì²´':\n",
        "                    center_lat = filtered_charger_df['ìœ„ë„'].mean()\n",
        "                    center_lon = filtered_charger_df['ê²½ë„'].mean()\n",
        "                    zoom_start = 9\n",
        "                else:\n",
        "                    center_lat = 36.5\n",
        "                    center_lon = 127.5\n",
        "                    zoom_start = 7\n",
        "\n",
        "                map_start_time = time.time()\n",
        "\n",
        "                with st.spinner(\"ì§€ë„ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\"):\n",
        "                    m = folium.Map(\n",
        "                        location=[center_lat, center_lon],\n",
        "                        zoom_start=zoom_start,\n",
        "                        tiles='OpenStreetMap'\n",
        "                    )\n",
        "\n",
        "                    if show_heatmap:\n",
        "                        heat_sample = filtered_charger_df.sample(n=min(len(filtered_charger_df), heatmap_limit), random_state=42)\n",
        "                        heat_data = heat_sample[['ìœ„ë„', 'ê²½ë„']].values.tolist()\n",
        "\n",
        "                        plugins.HeatMap(\n",
        "                            heat_data,\n",
        "                            radius=15,\n",
        "                            blur=15,\n",
        "                            max_zoom=13,\n",
        "                            gradient={0.2: 'blue', 0.4: 'lime', 0.6: 'yellow', 0.8: 'orange', 1: 'red'}\n",
        "                        ).add_to(m)\n",
        "                        if len(filtered_charger_df) > heatmap_limit:\n",
        "                            st.info(f\"ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ íˆíŠ¸ë§µì— {heatmap_limit:,}ê°œ ì§€ì ë§Œ í‘œì‹œë©ë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "                    if show_markers:\n",
        "                        marker_cluster = plugins.MarkerCluster(\n",
        "                            maxClusterRadius=50,\n",
        "                            disableClusteringAtZoom=10\n",
        "                        ).add_to(m)\n",
        "\n",
        "                        marker_sample = filtered_charger_df.sample(n=min(len(filtered_charger_df), marker_limit), random_state=42)\n",
        "\n",
        "                        for idx, row in marker_sample.iterrows():\n",
        "                            folium.Marker(\n",
        "                                location=[row['ìœ„ë„'], row['ê²½ë„']],\n",
        "                                popup=folium.Popup(\n",
        "                                    f\"<b>{row['ì¶©ì „ì†Œëª…']}</b><br>{row['ì£¼ì†Œ']}<br>ì„¤ì¹˜ë…„ë„: {int(row['ì„¤ì¹˜ë…„ë„'])}\",\n",
        "                                    max_width=300\n",
        "                                ),\n",
        "                                icon=folium.Icon(color='blue', icon='plug', prefix='fa')\n",
        "                            ).add_to(marker_cluster)\n",
        "                        if len(filtered_charger_df) > marker_limit:\n",
        "                            st.info(f\"ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ ë§ˆì»¤ëŠ” {marker_limit:,}ê°œë§Œ í‘œì‹œë©ë‹ˆë‹¤.\")\n",
        "\n",
        "\n",
        "                map_time = time.time() - map_start_time\n",
        "\n",
        "                tab1, tab2, tab3 = st.tabs([\"ì¶©ì „ì†Œ ì§€ë„\", \"ì—°ë„ë³„ ë¶„ì„\", \"ì‹œë„ë³„ ë¶„ì„\"])\n",
        "\n",
        "                with tab1:\n",
        "                    st.subheader(\"ì¶©ì „ì†Œ ìœ„ì¹˜ ì§€ë„\")\n",
        "                    st.markdown(\"\")\n",
        "                    # st.caption(f\"ì§€ë„ ìƒì„± ì‹œê°„: {map_time:.2f}ì´ˆ\")\n",
        "                    st_folium(m, width=900, height=600, returned_objects=[\"last_object_clicked\"])\n",
        "\n",
        "                with tab2:\n",
        "                    if not filtered_charger_df.empty:\n",
        "                        st.subheader(\"ì—°ë„ë³„ ì¶©ì „ì†Œ ì„¤ì¹˜ í˜„í™©\")\n",
        "                        st.markdown(\"\")\n",
        "                        year_trend = filtered_charger_df['ì„¤ì¹˜ë…„ë„'].value_counts().sort_index()\n",
        "                        year_trend_df = year_trend.reset_index()\n",
        "                        year_trend_df.columns = ['ì„¤ì¹˜ë…„ë„', 'ì¶©ì „ì†Œ ìˆ˜']\n",
        "                        # st.line_chart(year_trend_df.set_index('ì„¤ì¹˜ë…„ë„'))\n",
        "                        fig, ax = plt.subplots(figsize=(6,4))\n",
        "                        ax.plot(year_trend_df['ì„¤ì¹˜ë…„ë„'], year_trend_df['ì¶©ì „ì†Œ ìˆ˜'],\n",
        "                                marker='o', linewidth=2, markersize=6)\n",
        "                        ax.set_xlabel('ì„¤ì¹˜ë…„ë„')\n",
        "                        ax.set_ylabel('ì¶©ì „ì†Œ ìˆ˜')\n",
        "                        ax.grid(True, alpha=0.3)\n",
        "                        plt.tight_layout()\n",
        "                        st.pyplot(fig, use_container_width=False)\n",
        "                        plt.close(fig)\n",
        "                    else:\n",
        "                        st.warning(\"ì‹œë„ë³„ ì¶©ì „ì†Œ í˜„í™©ì„ í‘œì‹œí•  ì§€ì—­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "                with tab3:\n",
        "                    # st.subheader(\"ìƒì„¸ ë¶„ì„ ë³´ê¸°\")\n",
        "                    if not filtered_charger_df.empty:\n",
        "                        st.subheader(\"ì‹œë„ë³„ ì¶©ì „ì†Œ í˜„í™© (TOP 10)\")\n",
        "                        st.markdown(\"\")\n",
        "                        if 'ì‹œë„' in filtered_charger_df.columns:\n",
        "                            region_chart = filtered_charger_df['ì‹œë„'].value_counts().head(10)\n",
        "\n",
        "                            fig, ax = plt.subplots(figsize=(6,4))\n",
        "\n",
        "                            bars = ax.bar(region_chart.index, region_chart.values,\n",
        "                                            color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "\n",
        "                            ax.set_xlabel('ì‹œë„')\n",
        "                            ax.set_ylabel('ì¶©ì „ì†Œ ìˆ˜')\n",
        "                            ax.set_title('ì‹œë„ë³„ ì¶©ì „ì†Œ í˜„í™©')\n",
        "\n",
        "                            for bar in bars:\n",
        "                                height = bar.get_height()\n",
        "                                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                                        f'{int(height)}',\n",
        "                                        ha='center', va='bottom')\n",
        "\n",
        "                            plt.xticks(rotation=0)\n",
        "                            plt.tight_layout()\n",
        "                            st.pyplot(fig, use_container_width=False)\n",
        "                            plt.close(fig)\n",
        "                        else:\n",
        "                            st.warning(\"ì‹œë„ë³„ ì¶©ì „ì†Œ í˜„í™©ì„ í‘œì‹œí•  ì§€ì—­ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "            else:\n",
        "                st.warning(\"ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” ì¶©ì „ì†Œê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ ì¡°ì •í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "\n",
        "    elif st.session_state.current_page == \"ì£¼ìš” í† í”½\":\n",
        "        st.header(\"ì»¤ë®¤ë‹ˆí‹° ë‚´ ì „ê¸°ì°¨ ê´€ë ¨ ì£¼ìš” í‚¤ì›Œë“œ ë¶„ì„\")\n",
        "        st.write(\"**2020ë…„ ~ 2024ë…„, ë³´ë°°ë“œë¦¼ ê²Œì‹œê¸€**\")\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"\"\"\n",
        "        <div style=\"text-align: right; margin-top: -20px; margin-bottom: 20px;\">\n",
        "            <small style=\"color: #666;\">\n",
        "                ì¶œì²˜ : 2020ë…„ ~ 2024ë…„, ë³´ë°°ë“œë¦¼\n",
        "            </small>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        if not common_data['word_count']:\n",
        "            st.warning(\"ì›Œë“œí´ë¼ìš°ë“œë¥¼ ìƒì„±í•  í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. 'ele_crawling.csv' íŒŒì¼ê³¼ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "        else:\n",
        "\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                top_word = common_data['word_count'].most_common(1)[0][0]\n",
        "                st.metric(label=\"ì¸ê¸° ë‹¨ì–´\", value=top_word, delta=\"1ìœ„\")\n",
        "            with col2:\n",
        "                top_count = common_data['word_count'].most_common(1)[0][1]\n",
        "                st.metric(label=\"ì–¸ê¸‰ ìˆ˜\", value=f\"{top_count}ë²ˆ\", delta=\"ìµœê³ \")\n",
        "            with col3:\n",
        "                total_keywords = len(common_data['word_count'])\n",
        "                st.metric(label=\"ì´ ë‹¨ì–´\", value=f\"{total_keywords}ê°œ\", delta=\"ê³ ìœ  ë‹¨ì–´\")\n",
        "\n",
        "            try:\n",
        "                def create_circle_mask(size):\n",
        "                    y, x = np.ogrid[:size, :size]\n",
        "                    center = size / 2\n",
        "                    mask = (x - center) ** 2 + (y - center) ** 2 > (size/2) ** 2\n",
        "                    return mask.astype(int) * 255\n",
        "\n",
        "                mask = create_circle_mask(600)\n",
        "\n",
        "                wordcloud = WordCloud(width=1200,\n",
        "                                      height=800,\n",
        "                                      background_color='white',\n",
        "                                      font_path=font_path,\n",
        "                                      mask=mask,\n",
        "                                      collocations=False,\n",
        "                                      colormap='YlGnBu',\n",
        "                                      min_font_size=15,\n",
        "                                      max_font_size=100,\n",
        "                                      max_words=150,\n",
        "                                      relative_scaling=0.4\n",
        "                                      ).generate_from_frequencies(common_data['word_count'])\n",
        "                fig, ax = plt.subplots(figsize=(5,5), dpi=300)\n",
        "                ax.imshow(wordcloud, interpolation='bilinear')\n",
        "                ax.axis('off')\n",
        "                col_center = st.columns([1, 1.5, 1])\n",
        "                with col_center[1]:\n",
        "                    st.pyplot(fig, dpi=300)\n",
        "                plt.close(fig)\n",
        "            except Exception as e:\n",
        "                st.error(f\"ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì˜¤ë¥˜: {e}. 'konlpy' ì„¤ì¹˜ ë° í•œê¸€ í°íŠ¸(ë‚˜ëˆ”ê³ ë”•) ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "\n",
        "    elif st.session_state.current_page == \"ì¸í”„ë¼ í˜„í™©\":\n",
        "        st.header(\"ì¸í”„ë¼ í˜„í™© ë¶„ì„\")\n",
        "\n",
        "        tab1, tab2, tab3, tab4 = st.tabs([\"(2024ë…„) ì§€ì—­ë³„ ì „ê¸°ì°¨ ë¶„í¬\", \"ì§€ì—­ë³„ EV ë¹„ìœ¨\", \"(2024ë…„) ì§€ì—­ë³„ ì¶©ì „ê¸°ë‹¹ EV\", \"ì§€ì—­ë³„ ì¶©ì „ê¸°ë‹¹ EV\"])\n",
        "\n",
        "        with tab1:\n",
        "            st.subheader(\"ì§€ì—­ë³„ ì „ê¸°ì°¨ ë° ì¶©ì „ì†Œ ê²Œì´ì§€ë„ë„›\")\n",
        "\n",
        "            diagnosis_df = common_data['regional_summary'].copy()\n",
        "            diagnosis_df.rename(columns={\n",
        "                'name': 'ì§€ì—­',\n",
        "                'ev_counts': 'ì „ê¸°ì°¨ë“±ë¡ìˆ˜',\n",
        "                'charger_counts': 'ì¶©ì „ê¸°ìˆ˜'\n",
        "            }, inplace=True)\n",
        "\n",
        "            ev_list = diagnosis_df[\"ì „ê¸°ì°¨ë“±ë¡ìˆ˜\"].tolist()\n",
        "            ch_list = diagnosis_df[\"ì¶©ì „ê¸°ìˆ˜\"].tolist()\n",
        "            viz_data = list(zip(diagnosis_df[\"ì§€ì—­\"], ev_list, ch_list))\n",
        "\n",
        "            max_ev = max(ev_list) * 1.0\n",
        "            max_ch = max(ch_list) * 1.0\n",
        "\n",
        "            fig, axs = plt.subplots(1, len(viz_data), figsize=(len(viz_data)*2.6, 3.5), constrained_layout=True)\n",
        "            if len(viz_data) == 1:\n",
        "                axs = [axs]\n",
        "\n",
        "            for ax, (region, ev, ch) in zip(axs, viz_data):\n",
        "                ax.set_aspect(\"equal\")\n",
        "                ax.set_xlim(-1.2, 1.2)\n",
        "                ax.set_ylim(-1.2, 1.2)\n",
        "                ax.axis(\"off\")\n",
        "\n",
        "                ev_theta = (ev / max_ev) * 270\n",
        "                ch_theta = (ch / max_ch) * 270\n",
        "\n",
        "                ax.add_patch(patches.Wedge(\n",
        "                    center=(0, 0), r=1.0, theta1=135, theta2=135 + ev_theta,\n",
        "                    width=0.22, facecolor=\"#4F81BD\", alpha=0.9\n",
        "                ))\n",
        "                ax.add_patch(patches.Wedge(\n",
        "                    center=(0, 0), r=0.7, theta1=135, theta2=135 + ch_theta,\n",
        "                    width=0.22, facecolor=\"#C0504D\", alpha=0.85\n",
        "                ))\n",
        "\n",
        "                ax.text(0, -1.1, region, ha='center', fontsize=10, weight='bold')\n",
        "                ax.text(0, -1.3, f\"EV: {ev:,}\", ha='center', fontsize=9, color=\"#4F81BD\")\n",
        "                ax.text(0, -1.45, f\"ì¶©ì „ì†Œ: {ch:,}\", ha='center', fontsize=9, color=\"#C0504D\")\n",
        "\n",
        "            st.pyplot(fig)\n",
        "            plt.close(fig)\n",
        "\n",
        "            df_regional_display = common_data['regional_summary'].copy()\n",
        "            df_regional_display['ì „ê¸°ì°¨ë‹¹ ì¶©ì „ì†Œ'] = np.round(df_regional_display['charger_counts'] / df_regional_display['ev_counts'], 3)\n",
        "            df_regional_display.rename(columns={\n",
        "                'name': 'ì§€ì—­',\n",
        "                'ev_counts': 'ì „ê¸°ì°¨ (ëŒ€)',\n",
        "                'charger_counts': 'ì¶©ì „ì†Œ (ê°œ)',\n",
        "                'avg_ev_per_charger': 'ì¶©ì „ê¸° 1ê¸°ë‹¹ EV (í‰ê· )'\n",
        "            }, inplace=True)\n",
        "            st.dataframe(df_regional_display, use_container_width=True)\n",
        "\n",
        "\n",
        "        with tab3:\n",
        "            plot_ev_per_charger_2024(common_data['df_ev_chg_merge'])\n",
        "\n",
        "        with tab4:\n",
        "            plot_ev_per_charger_timeseries(common_data['df_ev_chg_merge'])\n",
        "\n",
        "            # 'ê²½ê¸°'ë¥¼ ì œì™¸í•œ ë°ì´í„°ë§Œ í•„í„°ë§\n",
        "            filtered_df = common_data['df_ev_chg_merge'][common_data['df_ev_chg_merge']['name'] != 'ê²½ê¸°']\n",
        "            # í•„í„°ë§ëœ ë°ì´í„°ë¡œ ê·¸ë˜í”„ ì¶œë ¥\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"íŠ¹ì´ê°’(ê²½ê¸°) ì œì™¸\")\n",
        "            plot_ev_per_charger_timeseries(filtered_df)\n",
        "\n",
        "\n",
        "        with tab2:\n",
        "            plot_ev_ratio_timeseries(common_data['df_ev_allcar_merge'])\n",
        "\n",
        "            # 'ì œì£¼'ë¥¼ ì œì™¸í•œ ë°ì´í„°ë§Œ í•„í„°ë§\n",
        "            filtered_df = common_data['df_ev_allcar_merge'][common_data['df_ev_allcar_merge']['name'] != 'ì œì£¼']\n",
        "            # í•„í„°ë§ëœ ë°ì´í„°ë¡œ ê·¸ë˜í”„ ì¶œë ¥\n",
        "            st.markdown(\"---\")\n",
        "            st.subheader(\"íŠ¹ì´ê°’(ì œì£¼) ì œì™¸\")\n",
        "            plot_ev_ratio_timeseries(filtered_df)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    elif st.session_state.current_page == \"ìƒê´€ë¶„ì„ê²°ê³¼\":\n",
        "        st.header(\"ìƒê´€ê´€ê³„ ë¶„ì„\")\n",
        "        plot_car_charger_correlation_national(common_data['df_car'], common_data['df_charger'])\n",
        "        st.markdown(\"---\")\n",
        "        st.subheader(\"ì§€ì—­ë³„ ì „ê¸°ì°¨ vs ì¶©ì „ì†Œ ìƒê´€ê´€ê³„ (ìµœì‹  ë°ì´í„°)\")\n",
        "        fig, correlation_regional = create_correlation_plot_regional(common_data)\n",
        "        st.pyplot(fig)\n",
        "        plt.close(fig)\n",
        "        col1, col2, col3 = st.columns(3)\n",
        "        with col1:\n",
        "            st.metric(\"ìƒê´€ê³„ìˆ˜ (ì§€ì—­ë³„)\", f\"{correlation_regional:.3f}\")\n",
        "        with col2:\n",
        "            st.metric(\"ê²°ì •ê³„ìˆ˜ (ì§€ì—­ë³„)\", f\"{correlation_regional**2:.3f}\")\n",
        "        with col3:\n",
        "            st.metric(\"í•´ì„\", \"ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„\" if correlation_regional > 0.7 else (\"ìŒì˜ ìƒê´€ê´€ê³„\" if correlation_regional < -0.3 else \"ì•½í•œ ìƒê´€ê´€ê³„\"))\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "\n",
        "\n",
        "\n",
        "    elif st.session_state.current_page == \"ë¶„ì„ ë¦¬í¬íŠ¸\":\n",
        "        st.header(\"ì¶©ì „ìŠ¤íŠ¸ë ˆìŠ¤\")\n",
        "        st.write(\"ê° ì§€ì—­ì˜ ì „ê¸°ì°¨ ìˆ˜ì™€ ì¶©ì „ì†Œ ìˆ˜ë¥¼ ë¹„êµí•˜ì—¬ ì¶©ì „ ìŠ¤íŠ¸ë ˆìŠ¤ ì •ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "        scores = []\n",
        "        recommendations = []\n",
        "        if not common_data['regional_summary'].empty:\n",
        "            max_ev_per_charger_val = common_data['regional_summary']['avg_ev_per_charger'].max()\n",
        "            min_ev_per_charger_val = common_data['regional_summary']['avg_ev_per_charger'].min()\n",
        "\n",
        "            for idx, row in common_data['regional_summary'].iterrows():\n",
        "                ev_per_charger = row['avg_ev_per_charger']\n",
        "                if pd.isna(ev_per_charger) or ev_per_charger == 0:\n",
        "                    score = 0\n",
        "                elif max_ev_per_charger_val == min_ev_per_charger_val:\n",
        "                    score = 50\n",
        "                else:\n",
        "                    score = ((max_ev_per_charger_val - ev_per_charger) / (max_ev_per_charger_val - min_ev_per_charger_val)) * 100\n",
        "\n",
        "                scores.append(round(score))\n",
        "\n",
        "                if score >= 70:\n",
        "                    recommendations.append(\"ğŸŸ¢ ë‚®ìŒ \")\n",
        "                elif score >= 50:\n",
        "                    recommendations.append(\"ğŸŸ¡ ë³´í†µ \")\n",
        "                elif score >= 30:\n",
        "                    recommendations.append(\"ğŸŸ  ë†’ìŒ \")\n",
        "                else:\n",
        "                    recommendations.append(\"ğŸ”´ ë§¤ìš° ë†’ìŒ \")\n",
        "\n",
        "        result_df = pd.DataFrame({\n",
        "            'ì§€ì—­': common_data['regions'],\n",
        "            'ì „ê¸°ì°¨ ìˆ˜': common_data['ev_counts'],\n",
        "            'ì¶©ì „ì†Œ ìˆ˜': common_data['charger_counts'],\n",
        "            'ì¶©ì „ê¸° 1ê¸°ë‹¹ ì „ê¸°ì°¨': common_data['regional_summary']['avg_ev_per_charger'].round(1).tolist(),\n",
        "            'ì¸í”„ë¼ ì ìˆ˜': scores,\n",
        "            'ì¶©ì „ ìŠ¤íŠ¸ë ˆìŠ¤': recommendations\n",
        "         })\n",
        "\n",
        "        st.dataframe(result_df.sort_values(by='ì¸í”„ë¼ ì ìˆ˜', ascending=False),\n",
        "                     use_container_width=True,\n",
        "                     hide_index=True\n",
        "                     )\n",
        "        st.markdown(\"\")\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "        # ë°ì´í„° ì •ë ¬\n",
        "        sorted_df = result_df.sort_values(by='ì¸í”„ë¼ ì ìˆ˜', ascending=True)  # ì°¨íŠ¸ìš©ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ\n",
        "\n",
        "        # ë°” ì°¨íŠ¸ ê·¸ë¦¬ê¸°\n",
        "        bars = ax.bar(sorted_df['ì§€ì—­'], sorted_df['ì¸í”„ë¼ ì ìˆ˜'],\n",
        "                      color='skyblue', edgecolor='navy', alpha=0.7)\n",
        "\n",
        "        # ê° ë°” ìœ„ì— ì ìˆ˜ í‘œì‹œ\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
        "                    f'{int(height)}',\n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        ax.set_xlabel('ì§€ì—­')\n",
        "        ax.set_ylabel('ì¸í”„ë¼ ì ìˆ˜')\n",
        "        ax.set_title('ì§€ì—­ë³„ ì¸í”„ë¼ ì ìˆ˜')\n",
        "        ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "        # ğŸ”§ xì¶• ê¸€ì ê°€ë¡œë¡œ ì„¤ì •\n",
        "        plt.xticks(rotation=0)  # 0ë„ = ê°€ë¡œ\n",
        "        plt.tight_layout()\n",
        "\n",
        "        st.pyplot(fig)\n",
        "        plt.close(fig)\n",
        "         # st.info(\"ğŸ’¡ ì¶”ì²œ ì ìˆ˜ëŠ” í•´ë‹¹ ì§€ì—­ì˜ ì „ê¸°ì°¨ ìˆ˜ ëŒ€ë¹„ ì¶©ì „ì†Œ ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ì „ê¸°ì°¨ ì¶©ì „ ì¸í”„ë¼ í™˜ê²½ì´ ë” ë‚˜ì˜ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    elif st.session_state.current_page == \"FAQ\":\n",
        "      st.header(\"ì „ê¸°ì°¨ FAQ ê²€ìƒ‰\")\n",
        "\n",
        "      col1, col2 = st.columns([4, 1])\n",
        "\n",
        "      with col1:\n",
        "          search_query = st.text_input(\n",
        "              \"ê²€ìƒ‰ì–´ ì…ë ¥\",\n",
        "              label_visibility=\"collapsed\"\n",
        "          )\n",
        "      with col2:\n",
        "          search_button = st.button(\"ê²€ìƒ‰\", type=\"primary\", use_container_width=True)\n",
        "\n",
        "      # ğŸ”¹ 2. íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
        "      csv_path = \"/content/crawling_car.csv\"\n",
        "      df = pd.read_csv(csv_path, encoding='cp949')  # ì§ˆë¬¸, ë‹µë³€ ì»¬ëŸ¼ ì¡´ì¬ ê°€ì •\n",
        "\n",
        "      # ğŸ”¹ 3. ëœë¤ ë‚ ì§œ ìƒì„± í•¨ìˆ˜\n",
        "      def random_date(start, end):\n",
        "          delta = end - start\n",
        "          random_days = random.randint(0, delta.days)\n",
        "          return (start + timedelta(days=random_days)).strftime('%Y-%m-%d')\n",
        "\n",
        "      # ğŸ”¹ 4. ë‚ ì§œ ë²”ìœ„ ë° ì¶œì²˜ ë¦¬ìŠ¤íŠ¸ ì„¤ì •\n",
        "      start_date = datetime.strptime(\"2023-01-01\", \"%Y-%m-%d\")\n",
        "      end_date = datetime.strptime(\"2024-12-31\", \"%Y-%m-%d\")\n",
        "      sources = [\"ê¸°ì•„\", \"í˜„ëŒ€\", \"í…ŒìŠ¬ë¼\"]\n",
        "\n",
        "      # ğŸ”¹ 5. FAQ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
        "      faq_data = []\n",
        "      for _, row in df.iterrows():\n",
        "          item = {\n",
        "              \"category\": \"ì „ê¸°ì°¨\",\n",
        "              \"question\": row[\"question\"],\n",
        "              \"answer\": row[\"answer\"],\n",
        "              \"source\": random.choice(sources),\n",
        "              \"date\": random_date(start_date, end_date),\n",
        "              \"views\": random.randint(100, 5000)\n",
        "          }\n",
        "          faq_data.append(item)\n",
        "\n",
        "      # ğŸ”¹ 6. ê²€ìƒ‰ ê²°ê³¼ í•„í„°ë§\n",
        "      if search_query:\n",
        "          filtered_faq = [\n",
        "              faq for faq in faq_data\n",
        "              if search_query.lower() in faq['question'].lower() or\n",
        "                search_query.lower() in faq['answer'].lower() or\n",
        "                search_query.lower() in faq['category'].lower()\n",
        "          ]\n",
        "      else:\n",
        "          filtered_faq = faq_data\n",
        "\n",
        "      # ğŸ”¹ 7. ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ í‘œì‹œ\n",
        "      st.metric(\"ê²€ìƒ‰ ê²°ê³¼\", f\"{len(filtered_faq)}ê±´\")\n",
        "      st.markdown(\"---\")\n",
        "\n",
        "      # ğŸ”¹ 8. FAQ ì¶œë ¥\n",
        "      if len(filtered_faq) == 0:\n",
        "          st.info(\"ğŸ” ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”.\")\n",
        "      else:\n",
        "          for i in range(0, len(filtered_faq), 2):\n",
        "              cols = st.columns(2)\n",
        "              for j in range(2):\n",
        "                  faq_index = i + j  # ğŸ”‘ ìœ ì¼í•œ ì¸ë±ìŠ¤ë¡œ í‚¤ ìƒì„±\n",
        "                  if faq_index < len(filtered_faq):\n",
        "                      faq = filtered_faq[faq_index]\n",
        "                      with cols[j]:\n",
        "                          with st.container():\n",
        "                              st.markdown(\n",
        "                                  f\"\"\"\n",
        "                                  <div style=\"\n",
        "                                      background-color: #f8f9fa;\n",
        "                                      padding: 20px;\n",
        "                                      border-radius: 10px;\n",
        "                                      border-left: 4px solid #4ECDC4;\n",
        "                                      margin-bottom: 10px;\n",
        "                                      height: 220px;\n",
        "                                  \">\n",
        "                                      <span style=\"\n",
        "                                          background-color: #4ECDC4;\n",
        "                                          color: white;\n",
        "                                          padding: 2px 8px;\n",
        "                                          border-radius: 4px;\n",
        "                                          font-size: 12px;\n",
        "                                      \">{faq['category']}</span>\n",
        "                                      <h4 style=\"margin-top: 10px; color: #2c3e50; font-size: 16px;\">\n",
        "                                          {faq['question']}\n",
        "                                      </h4>\n",
        "                                      <p style=\"color: #555; margin: 10px 0; font-size: 14px;\">\n",
        "                                          {str(faq['answer'])[:100]}...\n",
        "                                      </p>\n",
        "                                      <div style=\"\n",
        "                                          display: flex;\n",
        "                                          justify-content: space-between;\n",
        "                                          align-items: center;\n",
        "                                          margin-top: 15px;\n",
        "                                          font-size: 12px;\n",
        "                                          color: #888;\n",
        "                                      \">\n",
        "                                          <span>ğŸ“° {faq['source']}</span>\n",
        "                                          <span>ğŸ‘ï¸ {faq['views']:,}íšŒ</span>\n",
        "                                      </div>\n",
        "                                  </div>\n",
        "                                  \"\"\",\n",
        "                                  unsafe_allow_html=True\n",
        "                              )\n",
        "\n",
        "                              if st.button(\"ìì„¸íˆ ë³´ê¸°\", key=f\"detail_{faq_index}\", use_container_width=True):\n",
        "                                  with st.expander(\"ì „ì²´ ë‹µë³€\", expanded=True):\n",
        "                                      st.write(f\"**Q. {faq['question']}**\")\n",
        "                                      st.write(faq['answer'])\n",
        "                                      st.caption(f\"ì¶œì²˜: {faq['source']} | ì‘ì„±ì¼: {faq['date']}\")\n",
        "\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCxuJBrHtSZw",
        "outputId": "12cfe062-dab1-436f-d9b4-f35c36e70395"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.127.60.3\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Few9hDv3tUeL",
        "outputId": "0e99e2e9-172f-41ed-c6df-a1f14b77494a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.127.60.3:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kyour url is: https://curvy-walls-see.loca.lt\n",
            "NanumGothic font already configured.\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nuXE9l4A4eL_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}